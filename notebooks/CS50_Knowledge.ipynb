{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b531bb5-6ccc-4a21-bf74-4be096d5700b",
   "metadata": {},
   "source": [
    "# Knowledge Representation & Logic with Dimensions Research Data\n",
    "\n",
    "This notebook shows how to use **logic and knowledge representation** ideas with\n",
    "Dimensions-style research data (papers, authors, institutions, topics).\n",
    "\n",
    "1. **Modeling Research Data with Propositional Logic**\n",
    "   - Represent simple statements as propositional symbols.\n",
    "   - Build logical relationships like `P ∧ Q → R`.\n",
    "\n",
    "2. **Building a Knowledge Base (KB) for Research Trends**\n",
    "   - Facts and rules about topic trends.\n",
    "   - Simple forward chaining for inference.\n",
    "\n",
    "3. **Inference & Entailment in Research Analysis**\n",
    "   - Use logical implication to derive conclusions.\n",
    "   - Example: “Paper X is peer-reviewed” from journal facts.\n",
    "\n",
    "4. **Model Checking for Validating Hypotheses**\n",
    "   - Check whether a logical hypothesis holds in your data model.\n",
    "   - Example: “Collaboration between A and B → high citations”.\n",
    "\n",
    "5. **Automating Analysis with Logic Programming**\n",
    "   - Implement small rule-based queries in Python.\n",
    "   - Use rules to surface collaborations or high-impact areas.\n",
    "\n",
    "All examples use small toy DataFrames modeled on typical Dimensions exports.\n",
    "Adapt column names to match your actual pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a95764-c3c4-4dae-adb6-ffa1b0e90133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Optional: for propositional logic formulas\n",
    "# !pip install sympy\n",
    "from sympy import symbols\n",
    "from sympy.logic.boolalg import And, Or, Not, Implies, satisfiable\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# --- Toy \"papers\" table ---\n",
    "papers = pd.DataFrame({\n",
    "    \"paper_id\": [\"P1\", \"P2\", \"P3\"],\n",
    "    \"title\": [\n",
    "        \"AI methods for infectious disease modeling\",\n",
    "        \"Data repositories for immunology research\",\n",
    "        \"Collaborative networks in pandemic preparedness\"\n",
    "    ],\n",
    "    \"journal\": [\"JAI\", \"JDATA\", \"JAI\"],\n",
    "    \"primary_topic\": [\"AI\", \"DRKB\", \"Collab\"],\n",
    "    \"author\": [\"A1\", \"A2\", \"A1\"],\n",
    "    \"institution\": [\"NIAID\", \"UniversityX\", \"NIAID\"],\n",
    "    \"citations_5yr\": [120, 35, 80]\n",
    "})\n",
    "\n",
    "# --- Toy \"institutions\" table ---\n",
    "institutions = pd.DataFrame({\n",
    "    \"institution\": [\"NIAID\", \"UniversityX\", \"InstituteY\"],\n",
    "    \"specialty_topic\": [\"AI\", \"DRKB\", \"Vaccines\"]\n",
    "})\n",
    "\n",
    "# --- Toy \"collaborations\" table ---\n",
    "collabs = pd.DataFrame({\n",
    "    \"paper_id\": [\"P3\", \"P4\", \"P5\"],\n",
    "    \"inst_a\": [\"NIAID\", \"NIAID\", \"UniversityX\"],\n",
    "    \"inst_b\": [\"UniversityX\", \"InstituteY\", \"InstituteY\"],\n",
    "    \"citations_5yr\": [80, 10, 200]\n",
    "})\n",
    "\n",
    "# --- Toy topic trend table ---\n",
    "topic_trends = pd.DataFrame({\n",
    "    \"topic\": [\"AI\", \"DRKB\", \"Vaccines\"],\n",
    "    \"year\": [2019, 2020, 2021, 2019, 2020, 2021, 2019, 2020, 2021],\n",
    "    \"n_pubs\": [50, 70, 90,   20, 25, 22,    10, 12, 25]\n",
    "}).sort_values([\"topic\", \"year\"])\n",
    "\n",
    "topic_trends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130e306d-e1b0-47f8-a04f-c9363473ee69",
   "metadata": {},
   "source": [
    "## 1. Modeling Research Data with Propositional Logic\n",
    "\n",
    "Represent simple research facts as propositional symbols:\n",
    "\n",
    "- Let **P** represent “Paper X is published in Journal Y”.\n",
    "- Let **Q** represent “Author A is affiliated with Institution B”.\n",
    "- Let **R** represent “Institution B specializes in Topic Z”.\n",
    "\n",
    "Then a rule like:\n",
    "\n",
    "\\[\n",
    "P \\land Q \\rightarrow R\n",
    "\\]\n",
    "\n",
    "means: *If a paper by A is in that journal and A is at B, then B specializes in Z*.\n",
    "\n",
    "Here we’ll show:\n",
    "\n",
    "- How to map small data facts into propositional variables.\n",
    "- How to build a formula like `P & Q → R`.\n",
    "- How to check if a particular valuation (model) satisfies the formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0726bf1e-b7ad-466d-8816-3df6b87311ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define propositional symbols for one simple scenario\n",
    "P, Q, R = symbols(\"P Q R\")\n",
    "\n",
    "# Example formula: P ∧ Q → R\n",
    "formula = Implies(And(P, Q), R)\n",
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1649c16f-e19c-45a0-9713-689c96e6cf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a valuation (truth assignment) from toy data\n",
    "\n",
    "# Suppose we pick:\n",
    "paper = papers.loc[papers[\"paper_id\"] == \"P1\"].iloc[0]  # AI paper in JAI by A1 at NIAID\n",
    "inst = institutions.loc[institutions[\"institution\"] == paper[\"institution\"]].iloc[0]\n",
    "\n",
    "# Define propositions concretely:\n",
    "# P = \"Paper P1 is in JAI\" → True\n",
    "P_val = True\n",
    "\n",
    "# Q = \"Author A1 is affiliated with NIAID\" → True in this toy example\n",
    "Q_val = True\n",
    "\n",
    "# R = \"NIAID specializes in AI\" → check institutions table\n",
    "R_val = (inst[\"specialty_topic\"] == \"AI\")\n",
    "\n",
    "P_val, Q_val, R_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39cadb3-1561-44d9-ad3c-2ef90f4d496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the formula is satisfied under this valuation\n",
    "def eval_formula(f, assignment):\n",
    "    return bool(f.subs(assignment))\n",
    "\n",
    "assignment = {P: P_val, Q: Q_val, R: R_val}\n",
    "print(\"Formula:\", formula)\n",
    "print(\"Satisfied?\", eval_formula(formula, assignment))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655474a1-a705-4de9-b7ec-fa54ae37dc3b",
   "metadata": {},
   "source": [
    "## 2. Building a Knowledge Base (KB) for Research Trends\n",
    "\n",
    "Build a simple **knowledge base** of:\n",
    "\n",
    "- **Facts**: atomic statements derived directly from data.\n",
    "- **Rules**: implications linking conditions to conclusions.\n",
    "\n",
    "Example:\n",
    "\n",
    "- Fact: “In 2020, publications on topic T increased.”\n",
    "- Rule: “If there’s an increase in publications on topic T, then topic T is gaining research interest.”\n",
    "\n",
    "We’ll:\n",
    "\n",
    "1. Automatically create **increase facts** from `topic_trends`.\n",
    "2. Define a rule: `increase(T) → gaining_interest(T)`.\n",
    "3. Use a simple **forward-chaining** procedure to infer `gaining_interest(T)` for all topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535219c7-1421-4be1-af24-f813abec6c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: compute \"increase in topic T\" facts from topic_trends\n",
    "\n",
    "trend_facts = set()  # strings like \"increase(AI)\"\n",
    "\n",
    "for topic in topic_trends[\"topic\"].unique():\n",
    "    df_t = topic_trends[topic_trends[\"topic\"] == topic].sort_values(\"year\")\n",
    "    n = df_t[\"n_pubs\"].values\n",
    "    years = df_t[\"year\"].values\n",
    "\n",
    "    # Check if there's at least one increase year-over-year\n",
    "    increases = (n[1:] > n[:-1])\n",
    "    if increases.any():\n",
    "        trend_facts.add(f\"increase({topic})\")\n",
    "\n",
    "trend_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24df5354-ecbe-4b10-ab3c-3738a53ea50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define a simple rule: increase(T) => gaining_interest(T)\n",
    "\n",
    "rules = [\n",
    "    (\"increase(T)\", \"gaining_interest(T)\")\n",
    "]\n",
    "\n",
    "# Step 3: Forward chaining for this small Horn-clause subset\n",
    "\n",
    "def substitute(pattern, topic):\n",
    "    # pattern like \"increase(T)\" -> \"increase(AI)\"\n",
    "    return pattern.replace(\"T\", topic)\n",
    "\n",
    "def forward_chain_trends(facts, rules):\n",
    "    derived = set(facts)\n",
    "    changed = True\n",
    "\n",
    "    topics = topic_trends[\"topic\"].unique()\n",
    "\n",
    "    while changed:\n",
    "        changed = False\n",
    "        for (premise_pattern, conclusion_pattern) in rules:\n",
    "            for t in topics:\n",
    "                premise = substitute(premise_pattern, t)\n",
    "                conclusion = substitute(conclusion_pattern, t)\n",
    "                if premise in derived and conclusion not in derived:\n",
    "                    derived.add(conclusion)\n",
    "                    changed = True\n",
    "    return derived\n",
    "\n",
    "kb_trends = forward_chain_trends(trend_facts, rules)\n",
    "sorted(kb_trends)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68ead04-8bb8-4d8f-9915-9ba82b69a799",
   "metadata": {},
   "source": [
    "## 3. Inference & Entailment in Research Analysis\n",
    "\n",
    "**Logical entailment**:\n",
    "\n",
    "> A knowledge base KB entails sentence S (KB ⊨ S) if S is true in **all models** where KB is true.\n",
    "\n",
    "Example:\n",
    "\n",
    "- Premise 1: “All papers published in Journal J are peer-reviewed.”\n",
    "- Premise 2: “Paper X is published in Journal J.”\n",
    "- Conclusion: “Paper X is peer-reviewed.”\n",
    "\n",
    "We’ll encode:\n",
    "\n",
    "- A fact table for journals and their peer-review status.\n",
    "- A rule: `published_in(p, j) ∧ peer_reviewed_journal(j) → peer_reviewed(p)`.\n",
    "- A simple inference procedure to label peer-reviewed papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bee7634-cdf6-415b-95e8-5df277871212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy journal metadata\n",
    "journals = pd.DataFrame({\n",
    "    \"journal\": [\"JAI\", \"JDATA\"],\n",
    "    \"peer_reviewed\": [True, True]\n",
    "})\n",
    "\n",
    "# Build facts\n",
    "facts_pub = set()\n",
    "facts_journal = set()\n",
    "\n",
    "for _, row in papers.iterrows():\n",
    "    facts_pub.add(f\"published_in({row['paper_id']},{row['journal']})\")\n",
    "\n",
    "for _, row in journals.iterrows():\n",
    "    if row[\"peer_reviewed\"]:\n",
    "        facts_journal.add(f\"peer_reviewed_journal({row['journal']})\")\n",
    "\n",
    "facts_pub, facts_journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5366100-df78-4ced-b994-66aa18303b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule: published_in(P, J) ∧ peer_reviewed_journal(J) → peer_reviewed(P)\n",
    "\n",
    "def infer_peer_reviewed(papers, facts_pub, facts_journal):\n",
    "    derived = set()\n",
    "    for fact in facts_pub:\n",
    "        # fact looks like published_in(P1,JAI)\n",
    "        inside = fact[len(\"published_in(\"):-1]\n",
    "        p_id, j_id = inside.split(\",\")\n",
    "        if f\"peer_reviewed_journal({j_id})\" in facts_journal:\n",
    "            derived.add(f\"peer_reviewed({p_id})\")\n",
    "    return derived\n",
    "\n",
    "peer_reviewed_facts = infer_peer_reviewed(papers, facts_pub, facts_journal)\n",
    "peer_reviewed_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c801c710-0602-4fc5-a930-f177a6bf7e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach as a column to papers (KB entails \"peer_reviewed(P)\" for these)\n",
    "papers[\"peer_reviewed\"] = papers[\"paper_id\"].apply(\n",
    "    lambda pid: f\"peer_reviewed({pid})\" in peer_reviewed_facts\n",
    ")\n",
    "papers[[\"paper_id\", \"journal\", \"peer_reviewed\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d1cfc8-4a53-4294-92ed-e0b913d5f2b1",
   "metadata": {},
   "source": [
    "## 4. Model Checking for Validating Hypotheses\n",
    "\n",
    "**Model checking**: verify whether a logical hypothesis holds in a particular model (dataset).\n",
    "\n",
    "Example hypothesis:\n",
    "\n",
    "> H: \"Collaboration between Institutions A and B leads to high citation counts.\"\n",
    "\n",
    "We can interpret this as the implication:\n",
    "\n",
    "\\[\n",
    "\\forall \\text{papers } p, (collab(p, A, B) \\rightarrow \\text{high_citations}(p))\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- `collab(p, A, B)` means paper p involves A and B.\n",
    "- `high_citations(p)` means citations_5yr ≥ threshold.\n",
    "\n",
    "To model check H on our data:\n",
    "\n",
    "1. Identify all collaborative papers between A and B.\n",
    "2. Check if any of them violates `high_citations` (counterexamples).\n",
    "3. If there are no counterexamples in the dataset, H holds in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e66098-7954-472d-b63e-f73abd66dc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIGH_CIT_THRESHOLD = 50\n",
    "\n",
    "def check_collab_hypothesis(collabs_df, inst_a, inst_b, threshold=HIGH_CIT_THRESHOLD):\n",
    "    # Select collabs between inst_a and inst_b (order-insensitive)\n",
    "    mask = (\n",
    "        ((collabs_df[\"inst_a\"] == inst_a) & (collabs_df[\"inst_b\"] == inst_b)) |\n",
    "        ((collabs_df[\"inst_a\"] == inst_b) & (collabs_df[\"inst_b\"] == inst_a))\n",
    "    )\n",
    "    subs = collabs_df[mask]\n",
    "\n",
    "    if subs.empty:\n",
    "        return {\n",
    "            \"holds\": None,\n",
    "            \"reason\": \"No collaborations between these institutions in the data.\",\n",
    "            \"counterexamples\": []\n",
    "        }\n",
    "\n",
    "    # Counterexamples: collab with citations < threshold\n",
    "    counter = subs[subs[\"citations_5yr\"] < threshold]\n",
    "\n",
    "    return {\n",
    "        \"holds\": counter.empty,\n",
    "        \"reason\": \"No counterexamples found.\" if counter.empty else \"Some collaborations have low citations.\",\n",
    "        \"counterexamples\": counter.to_dict(orient=\"records\")\n",
    "    }\n",
    "\n",
    "# Example: hypothesis \"NIAID and UniversityX collabs → high citations\"\n",
    "res_h = check_collab_hypothesis(collabs, \"NIAID\", \"UniversityX\")\n",
    "res_h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf55a67f-993c-4915-af88-7134a11a55e0",
   "metadata": {},
   "source": [
    "## 5. Automating Analysis with Logic Programming\n",
    "\n",
    "Logic programming (e.g., Prolog) lets you:\n",
    "\n",
    "- Declare **facts** and **rules**.\n",
    "- Ask **queries** like “Which collaborations are high-impact and AI-related?”\n",
    "\n",
    "We’ll emulate a tiny slice of logic programming in Python:\n",
    "\n",
    "- Facts:\n",
    "  - `collab(inst_a, inst_b, topic, citations)`\n",
    "- Rules:\n",
    "  - `high_impact_collab(A,B) :- collab(A,B,Topic,C), C >= threshold`\n",
    "  - `ai_collab(A,B) :- collab(A,B,Topic,C), Topic = AI`\n",
    "\n",
    "Then we’ll write simple query functions that behave like Prolog predicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd902d04-44e8-456e-baa0-9d3f3cef11fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a fact table for collaborations enriched with topic\n",
    "\n",
    "# Join collabs with papers to get topic for known paper_ids\n",
    "collab_enriched = collabs.merge(\n",
    "    papers[[\"paper_id\", \"primary_topic\"]],\n",
    "    on=\"paper_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "collab_enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75348cea-fc24-47e7-b063-59bd256b70b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facts as a list of tuples: (inst_a, inst_b, topic, citations)\n",
    "facts_collab = [\n",
    "    (row[\"inst_a\"], row[\"inst_b\"], row[\"primary_topic\"], row[\"citations_5yr\"])\n",
    "    for _, row in collab_enriched.iterrows()\n",
    "]\n",
    "\n",
    "facts_collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cf53e2-d216-4ba6-b9d9-a9860dd78751",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIGH_IMPACT = 50\n",
    "\n",
    "def high_impact_collab(facts, threshold=HIGH_IMPACT):\n",
    "    \"\"\"\n",
    "    Logic rule: high_impact_collab(A,B) :- collab(A,B,Topic,C), C >= threshold\n",
    "    Returns set of (A,B) pairs.\n",
    "    \"\"\"\n",
    "    result = set()\n",
    "    for (A, B, topic, C) in facts:\n",
    "        if C >= threshold:\n",
    "            # normalize pair ordering\n",
    "            pair = tuple(sorted((A, B)))\n",
    "            result.add(pair)\n",
    "    return result\n",
    "\n",
    "def ai_collab(facts):\n",
    "    \"\"\"\n",
    "    Logic rule: ai_collab(A,B) :- collab(A,B,Topic,C), Topic = 'AI'\n",
    "    \"\"\"\n",
    "    result = set()\n",
    "    for (A, B, topic, C) in facts:\n",
    "        if topic == \"AI\":\n",
    "            pair = tuple(sorted((A, B)))\n",
    "            result.add(pair)\n",
    "    return result\n",
    "\n",
    "def high_impact_ai_collab(facts, threshold=HIGH_IMPACT):\n",
    "    \"\"\"\n",
    "    Conjunction of rules:\n",
    "    high_impact_ai_collab(A,B) :- high_impact_collab(A,B), ai_collab(A,B)\n",
    "    \"\"\"\n",
    "    hi = high_impact_collab(facts, threshold)\n",
    "    ai = ai_collab(facts)\n",
    "    return hi.intersection(ai)\n",
    "\n",
    "high_impact_pairs = high_impact_collab(facts_collab)\n",
    "ai_pairs = ai_collab(facts_collab)\n",
    "hi_ai_pairs = high_impact_ai_collab(facts_collab)\n",
    "\n",
    "high_impact_pairs, ai_pairs, hi_ai_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1f6043-c7b3-46c9-a564-71dcbc36c36d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. **Propositional Logic**\n",
    "   - Modeled simple statements like:\n",
    "     - Paper–journal relationships\n",
    "     - Author–institution affiliations\n",
    "     - Institution–topic specialties\n",
    "   - Built and evaluated implications such as `P ∧ Q → R`.\n",
    "\n",
    "2. **Knowledge Base for Trends**\n",
    "   - Derived `increase(T)` facts from topic counts.\n",
    "   - Used rules like `increase(T) → gaining_interest(T)` with forward-chaining.\n",
    "\n",
    "3. **Inference & Entailment**\n",
    "   - Encoded journal peer-review facts and rules.\n",
    "   - Derived `peer_reviewed(P)` for papers in peer-reviewed journals.\n",
    "\n",
    "4. **Model Checking**\n",
    "   - Interpreted hypotheses as implications on the data.\n",
    "   - Checked for counterexamples to statements like:\n",
    "     - “Collab(A,B) → high citations.”\n",
    "\n",
    "5. **Logic Programming-Style Automation**\n",
    "   - Represented collaborations as facts.\n",
    "   - Implemented simple rule-based queries (high-impact, AI-related collabs).\n",
    "\n",
    "You can extend this framework to:\n",
    "\n",
    "- Richer rule sets (e.g., disease areas, division-level logic, equity criteria).\n",
    "- More expressive logics (first-order, description logics).\n",
    "- Integration with formal tools (e.g., Prolog, Z3, PyDatalog) for heavier reasoning tasks.\n",
    "\n",
    "This module complements your ML / ANN / NLP / Optimization / Uncertainty modules by providing a **symbolic reasoning layer** for your NIAID/NIH research intelligence workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a0b8b9-ab7a-4fc0-9184-5f1f112d3eae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
