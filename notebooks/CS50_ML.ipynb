{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b887d96-60f9-4bcf-b74b-23e3d4dea143",
   "metadata": {},
   "source": [
    "# Core Machine Learning with Dimensions Grant Data\n",
    "\n",
    "This notebook introduces **core ML concepts** using Dimensions-style grant data:\n",
    "\n",
    "1. **Supervised Learning**\n",
    "   - Classification: k-NN, Perceptron, SVM\n",
    "   - Regression\n",
    "   - Loss functions (0–1, L₁, L₂)\n",
    "   - Overfitting & Regularization\n",
    "   - Validation: holdout & k-fold cross-validation\n",
    "\n",
    "2. **Unsupervised Learning**\n",
    "   - Clustering and k-means\n",
    "\n",
    "3. **Reinforcement Learning**\n",
    "   - Markov Decision Process (MDP) intuition\n",
    "   - Q-Learning with ε-greedy policy\n",
    "\n",
    "4. **Tools**\n",
    "   - `scikit-learn` models: Perceptron, SVM, KNeighborsClassifier, Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c0294e-6007-410a-85c2-ecc701cc6dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load your Dimensions-style data\n",
    "# grants = pd.read_csv(\"grants.csv\")\n",
    "\n",
    "print(\"Columns:\", grants.columns.tolist())\n",
    "\n",
    "# Example: verify we have the needed columns (adapt if your names differ)\n",
    "expected_cols = [\n",
    "    \"grant_id\",\n",
    "    \"topic_ai_score\",\n",
    "    \"topic_bioinfo_score\",\n",
    "    \"topic_data_repo_score\",\n",
    "    \"total_funding\",\n",
    "    \"citations_5yr\",\n",
    "    \"is_ai_ml\"\n",
    "]\n",
    "missing = [c for c in expected_cols if c not in grants.columns]\n",
    "if missing:\n",
    "    print(\"WARNING: Missing columns:\", missing)\n",
    "else:\n",
    "    print(\"All expected columns found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcd0600-7d4b-4770-a613-cf9a638ca7f6",
   "metadata": {},
   "source": [
    "## 1. Supervised Learning\n",
    "\n",
    "Supervised learning learns a function that maps **inputs → outputs** given labeled examples.\n",
    "\n",
    "\n",
    "- **Inputs (features):** topic scores + log-transformed funding\n",
    "- **Outputs (labels):**\n",
    "  - Classification: `is_ai_ml` (AI vs non-AI grant)\n",
    "  - Regression: `citations_5yr` (continuous)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21afd9d1-9b6d-47fb-ad32-0af533a05bb1",
   "metadata": {},
   "source": [
    "#### Feature and Label Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4f3b73-d7da-4e87-b4ca-735215e63361",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"topic_ai_score\", \"topic_bioinfo_score\", \"topic_data_repo_score\", \"total_funding\"]\n",
    "\n",
    "df = grants.copy()\n",
    "df[features] = df[features].fillna(0.0)\n",
    "df[\"total_funding\"] = np.log1p(df[\"total_funding\"])  # stabilize\n",
    "df[\"citations_5yr\"] = df[\"citations_5yr\"].fillna(0.0)\n",
    "df[\"is_ai_ml\"] = df[\"is_ai_ml\"].fillna(0).astype(int)\n",
    "\n",
    "X = df[features].values\n",
    "y_class = df[\"is_ai_ml\"].values\n",
    "y_reg = df[\"citations_5yr\"].values\n",
    "\n",
    "X_train, X_test, y_train_class, y_test_class = train_test_split(\n",
    "    X, y_class, test_size=0.2, random_state=42, stratify=y_class\n",
    ")\n",
    "\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X, y_reg, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a077fc96-db63-43d5-8953-32be8a00708c",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors (k-NN)\n",
    "\n",
    "For a new grant, k-NN:\n",
    "\n",
    "1. Finds the **k closest** training examples in feature space.\n",
    "2. Predicts the **majority class** among those neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7a3b20-a431-4761-bd53-6479e2e0950f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train_class)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "print(\"k-NN accuracy:\", accuracy_score(y_test_class, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa24f831-07a5-481c-bb12-389df3b7a9fa",
   "metadata": {},
   "source": [
    "### Perceptron\n",
    "\n",
    "A Perceptron:\n",
    "\n",
    "- Computes a weighted sum of inputs + bias.\n",
    "- Applies a step-like decision function.\n",
    "- Adjusts weights via updates based on misclassified examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ccf4c9-529f-486f-8f31-95bf5343dabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc = Perceptron(max_iter=1000, eta0=0.1, random_state=42)\n",
    "perc.fit(X_train, y_train_class)\n",
    "y_pred_perc = perc.predict(X_test)\n",
    "print(\"Perceptron accuracy:\", accuracy_score(y_test_class, y_pred_perc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4018dc9-21d2-4dcf-a5b9-e1922913e57d",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)\n",
    "\n",
    "SVM:\n",
    "\n",
    "- Finds the boundary that **maximizes the margin** between classes.\n",
    "- Can handle non-linear separation via kernels (e.g. RBF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbea818-b2a7-4ec9-b01a-0a4bc704522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\", random_state=42)\n",
    "svm.fit(X_train, y_train_class)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "print(\"SVM accuracy:\", accuracy_score(y_test_class, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda9f323-7f25-4fa4-9e56-5f6b8fc5f643",
   "metadata": {},
   "source": [
    "### Regression\n",
    "\n",
    "Goal: predict **continuous values**, e.g. `citations_5yr`.\n",
    "\n",
    "- Fit a simple linear regression model.\n",
    "- Evaluate using:\n",
    "  - **L₁ loss:** mean absolute error (MAE)\n",
    "  - **L₂ loss:** mean squared error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce01142-f8b1-4e3c-9e5e-4555c86dd2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train_reg, y_train_reg)\n",
    "y_pred_reg = reg.predict(X_test_reg)\n",
    "\n",
    "mae = mean_absolute_error(y_test_reg, y_pred_reg)  # L1\n",
    "mse = mean_squared_error(y_test_reg, y_pred_reg)   # L2\n",
    "\n",
    "print(\"Regression MAE (L1):\", mae)\n",
    "print(\"Regression MSE (L2):\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48907de-f62a-4156-b56e-b75c5897c8ed",
   "metadata": {},
   "source": [
    "### Loss Functions\n",
    "\n",
    "- **0–1 Loss (classification):** 1 if prediction ≠ truth, else 0.\n",
    "- **L₁ Loss (regression):** |y − ŷ|\n",
    "- **L₂ Loss (regression):** (y − ŷ)²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9c68ef-64a2-4dc5-8745-ed54af6acbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0–1 loss for SVM classifier\n",
    "zero_one_loss_svm = np.mean(y_test_class != y_pred_svm)\n",
    "print(\"0-1 loss (SVM classification):\", zero_one_loss_svm)\n",
    "\n",
    "# L1 and L2 for regression (already partly computed)\n",
    "l1_manual = np.mean(np.abs(y_test_reg - y_pred_reg))\n",
    "l2_manual = np.mean((y_test_reg - y_pred_reg) ** 2)\n",
    "print(\"Manual L1:\", l1_manual, \"Manual L2:\", l2_manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7bf68b-75a9-4ebf-9af7-e842061e42d1",
   "metadata": {},
   "source": [
    "### Overfitting & Regularization\n",
    "\n",
    "- **Overfitting:** model fits training data too closely, fails to generalize.\n",
    "- **Regularization:** penalizes overly complex models.\n",
    "\n",
    "Example: Logistic Regression with **L₂ penalty**:\n",
    "- Large `C` → weak regularization → higher risk of overfitting.\n",
    "- Small `C` → stronger regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd84965-7807-495d-add9-e51605cabef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Weak regularization (large C)\n",
    "logit_weak = LogisticRegression(C=1000.0, penalty=\"l2\", max_iter=1000)\n",
    "logit_weak.fit(X_train, y_train_class)\n",
    "proba_weak = logit_weak.predict_proba(X_test)[:, 1]\n",
    "auc_weak = roc_auc_score(y_test_class, proba_weak)\n",
    "\n",
    "# Strong regularization (small C)\n",
    "logit_strong = LogisticRegression(C=0.1, penalty=\"l2\", max_iter=1000)\n",
    "logit_strong.fit(X_train, y_train_class)\n",
    "proba_strong = logit_strong.predict_proba(X_test)[:, 1]\n",
    "auc_strong = roc_auc_score(y_test_class, proba_strong)\n",
    "\n",
    "print(\"AUC with weak regularization (C=1000):\", auc_weak)\n",
    "print(\"AUC with strong regularization (C=0.1):\", auc_strong)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1737c4-eff4-424c-8f79-00568fa47288",
   "metadata": {},
   "source": [
    "### Validation\n",
    "\n",
    "- **Holdout:** one-time train/test split (we’ve already used this).\n",
    "- **k-Fold Cross-Validation:** rotate which fold is used for testing to get more stable performance estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed9788-32cb-4cfc-81d3-21e6bda13371",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "svm_cv = SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\", random_state=42)\n",
    "\n",
    "cv_scores = cross_val_score(svm_cv, X, y_class, cv=kf, scoring=\"accuracy\")\n",
    "\n",
    "print(\"5-fold CV accuracies:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6e112f-7503-44e2-8d8b-8bf48d47ebb9",
   "metadata": {},
   "source": [
    "## 2. Unsupervised Learning\n",
    "\n",
    "Unsupervised learning finds **patterns without labels**.\n",
    "\n",
    "### Clustering\n",
    "\n",
    "- Groups similar data points.\n",
    "- We’ll use **k-means** to cluster grants based on topic and funding features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f199cd8-bb82-4aad-82ec-785c75a6a3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(X)\n",
    "\n",
    "df[\"cluster\"] = cluster_labels\n",
    "print(df[[\"grant_id\", \"cluster\"]].head())\n",
    "\n",
    "# Inspect cluster centers\n",
    "centers = pd.DataFrame(kmeans.cluster_centers_, columns=features)\n",
    "centers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff8b1cf-3951-4d2f-bfa9-3f423d4b9f3e",
   "metadata": {},
   "source": [
    "## 3. Reinforcement Learning\n",
    "\n",
    "RL learns by **trial and error** via feedback (rewards).\n",
    "\n",
    "**Markov Decision Process (MDP)**:\n",
    "- **States (s):** describe environment (e.g., grant type).\n",
    "- **Actions (a):** decisions (e.g., fund vs not fund).\n",
    "- **Transition model:** how actions move between states.\n",
    "- **Reward function:** immediate feedback.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803b5223-f6d6-483e-a6c1-0f1fdadce1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretize AI score into 3 bins → states\n",
    "ai_score = df[\"topic_ai_score\"].fillna(0.0)\n",
    "df[\"state\"] = pd.qcut(ai_score, q=3, labels=False, duplicates=\"drop\")\n",
    "\n",
    "env_grants = df[[\"grant_id\", \"state\", \"citations_5yr\"]].dropna().head(500)\n",
    "\n",
    "n_states = env_grants[\"state\"].nunique()\n",
    "n_actions = 2   # 0 = don't fund, 1 = fund\n",
    "\n",
    "Q = np.zeros((n_states, n_actions))\n",
    "\n",
    "alpha = 0.1   # learning rate\n",
    "gamma = 0.9   # discount factor\n",
    "epsilon = 0.1 # exploration rate\n",
    "\n",
    "def choose_action(state):\n",
    "    if np.random.rand() < epsilon:\n",
    "        return np.random.randint(0, n_actions)  # explore\n",
    "    return int(np.argmax(Q[state]))             # exploit\n",
    "\n",
    "def reward_function(row, action):\n",
    "    if action == 1:  # fund\n",
    "        return float(row[\"citations_5yr\"] / 10.0)\n",
    "    else:            # don't fund\n",
    "        return 0.0\n",
    "\n",
    "# Simple episodic loop: each episode iterates over grants\n",
    "for episode in range(50):\n",
    "    for _, g in env_grants.iterrows():\n",
    "        s = int(g[\"state\"])\n",
    "        a = choose_action(s)\n",
    "        r = reward_function(g, a)\n",
    "        s_next = s  # one-step toy environment\n",
    "\n",
    "        best_next = np.max(Q[s_next])\n",
    "        Q[s, a] = Q[s, a] + alpha * (r + gamma * best_next - Q[s, a])\n",
    "\n",
    "print(\"Learned Q-table (state × action):\")\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d812b5f8-aad1-40b3-81c4-082fa292a8b4",
   "metadata": {},
   "source": [
    "## 4. Tools: scikit-learn Models\n",
    "\n",
    "`scikit-learn` provides consistent APIs for:\n",
    "\n",
    "- **Classification**\n",
    "  - `KNeighborsClassifier`\n",
    "  - `Perceptron`\n",
    "  - `SVC` (Support Vector Machine)\n",
    "  - `NaiveBayes` variants (`GaussianNB`, `MultinomialNB`, etc.)\n",
    "- **Regression**\n",
    "  - `LinearRegression`, `Ridge`, `Lasso`, etc.\n",
    "- **Clustering**\n",
    "  - `KMeans`, `DBSCAN`, etc.\n",
    "\n",
    "Below: small “cheat sheet” instantiating and fitting the main models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9746994-b0c1-432f-ac81-2127aecc7ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-NN\n",
    "knn = KNeighborsClassifier(n_neighbors=5).fit(X_train, y_train_class)\n",
    "\n",
    "# Perceptron\n",
    "perc = Perceptron(max_iter=1000, eta0=0.1, random_state=42).fit(X_train, y_train_class)\n",
    "\n",
    "# SVM\n",
    "svm = SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\", random_state=42).fit(X_train, y_train_class)\n",
    "\n",
    "# Naive Bayes (Gaussian - good for continuous features)\n",
    "gnb = GaussianNB().fit(X_train, y_train_class)\n",
    "\n",
    "print(\"k-NN prediction sample:\", knn.predict(X_test[:5]))\n",
    "print(\"Perceptron prediction sample:\", perc.predict(X_test[:5]))\n",
    "print(\"SVM prediction sample:\", svm.predict(X_test[:5]))\n",
    "print(\"GaussianNB prediction sample:\", gnb.predict(X_test[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6be465-c487-4f0a-a163-3efc7dbe6924",
   "metadata": {},
   "source": [
    "1. **Supervised Learning**\n",
    "   - k-NN, Perceptron, SVM for classification\n",
    "   - Linear regression for citations\n",
    "   - Loss functions (0–1, L₁, L₂)\n",
    "   - Overfitting & regularization with logistic regression\n",
    "   - Holdout and k-fold cross-validation\n",
    "\n",
    "2. **Unsupervised Learning**\n",
    "   - k-means clustering on grant features\n",
    "\n",
    "3. **Reinforcement Learning**\n",
    "   - Toy Q-learning example with discretized grant “states”\n",
    "\n",
    "4. **Tools**\n",
    "   - `scikit-learn` classifiers, regressors, and clustering models\n",
    "\n",
    "This notebook forms your **core ML module** built directly on top of Dimensions grant data.  \n",
    "You can now plug in different features (abstract embeddings, PI country, disease tags) or different labels (funding decisions, impact tiers) with the same patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5b4c80-1e1c-4a16-b170-a2f7230d585b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
