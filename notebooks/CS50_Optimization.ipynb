{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38618545-2d9f-407b-a96a-5c1702e10781",
   "metadata": {},
   "source": [
    "# Optimization & Search with Dimensions Grant Data\n",
    "\n",
    "This notebook connects classic AI optimization techniques to **Dimensions-style grants data**:\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Local Search\n",
    "\n",
    "Local search maintains a **single state** and explores **neighbor states** to improve an objective.\n",
    "\n",
    "- **Objective function**: to be maximized (e.g., total similarity).\n",
    "- **Cost function**: to be minimized (e.g., mismatch error).\n",
    "- **Current state**: present configuration (e.g., mapping of grants → initiatives/programs).\n",
    "- **Neighbor state**: a slight variation (e.g., move one grant to a different initiative).\n",
    "\n",
    "local search to:\n",
    "- Categorize grants into initiatives.\n",
    "- Minimize mismatch between abstracts and assigned programs.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Linear Programming (LP)\n",
    "\n",
    "Linear programming optimizes a **linear objective** subject to **linear constraints**.\n",
    "\n",
    "LP to:\n",
    "- Allocate a limited budget across grants to maximize impact (citations).\n",
    "- Add equity constraints (e.g., minimum share to LMICs, minimum share per initiative).\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Constraint Satisfaction Problems (CSPs)\n",
    "\n",
    "CSPs assign values to variables while satisfying constraints.\n",
    "\n",
    "CSP formulations to:\n",
    "- Assign reviewers to grants.\n",
    "- Respect constraints: minimum reviewers per grant, max load per reviewer, conflicts-of-interest, topic fit.\n",
    "\n",
    "---\n",
    "\n",
    "## Dimensions Grants Examples (Summary)\n",
    "\n",
    "| Technique             | Problem Type                         | Dimensions Grants Example                                      |\n",
    "|-----------------------|--------------------------------------|----------------------------------------------------------------|\n",
    "| Local Search          | Approximate optimization             | Categorize grants into initiatives; minimize abstract–program mismatch |\n",
    "| Linear Programming    | Exact linear optimization            | Budget funding to maximize impact under cost & equity constraints |\n",
    "| Constraint Satisfaction | Valid assignments under constraints | Assign reviewers; match reviewers to grants with conflicts & topic constraints |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4370d09b-e6c0-4de0-ba03-1880c82448f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Local search helpers\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Linear programming\n",
    "import pulp\n",
    "\n",
    "# For CSP / reviewer assignment\n",
    "from collections import defaultdict\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# --- Load your data ---\n",
    "\n",
    "# 1) Grants (Dimensions-based)\n",
    "# grants = pd.read_csv(\"grants.csv\")\n",
    "# Expected columns:\n",
    "#   grant_id, abstract, program_code, initiative, total_funding, citations_5yr,\n",
    "#   country_income_level, topic_ai_score, topic_data_repo_score, ...\n",
    "\n",
    "# 2) Reviewers\n",
    "# reviewers = pd.read_csv(\"reviewers.csv\")\n",
    "# Expected columns:\n",
    "#   reviewer_id, expertise_topics (text), max_load\n",
    "\n",
    "# 3) Conflicts of interest\n",
    "# conflicts = pd.read_csv(\"conflicts.csv\")\n",
    "# Expected columns:\n",
    "#   grant_id, reviewer_id\n",
    "\n",
    "print(\"Grants columns:\", grants.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f340045f-46e4-47a9-9637-8d5bb1409e94",
   "metadata": {},
   "source": [
    "## 1.1 Local Search: Categorize Grants into Initiatives\n",
    "\n",
    "**Idea:**\n",
    "\n",
    "- Each grant gets assigned to one of a small set of **initiatives** (AI/ML, DMC, DRKB, etc.).\n",
    "- We want assignments where each grant’s abstract is **similar** to its initiative “profile”.\n",
    "- This is like clustering, but we’ll express it explicitly as **local search**:\n",
    "\n",
    "- **State**: mapping `grant_id → initiative`.\n",
    "- **Neighbor**: move a single grant to a different initiative.\n",
    "- **Objective**: maximize sum of cosine similarities between each grant and its initiative centroid.\n",
    "- **Algorithm**: hill climbing (steepest-ascent or first-choice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56db07f1-39b8-4900-8b5b-a80729258701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example initiative keyword seeds (tune for your portfolio)\n",
    "initiative_keywords = {\n",
    "    \"AI_ML\": [\"machine learning\", \"deep learning\", \"neural network\", \"prediction\"],\n",
    "    \"CB_SM\": [\"systems model\", \"simulation\", \"computational biology\"],\n",
    "    \"DRKB\": [\"database\", \"repository\", \"knowledgebase\", \"portal\"],\n",
    "    \"DMC\":  [\"data coordinating center\", \"data management center\"],\n",
    "    \"CWD\":  [\"training\", \"workshop\", \"curriculum\", \"career development\"],\n",
    "    \"SE\":   [\"software tool\", \"pipeline\", \"platform\", \"open-source\"]\n",
    "}\n",
    "\n",
    "# Use abstracts to create a TF-IDF space\n",
    "vectorizer = TfidfVectorizer(max_df=0.8, min_df=3, ngram_range=(1, 2))\n",
    "X = vectorizer.fit_transform(grants[\"abstract\"].fillna(\"\"))\n",
    "\n",
    "grant_ids = grants[\"grant_id\"].tolist()\n",
    "grant_vecs = X\n",
    "\n",
    "# Convert keyword lists into initial initiative vectors\n",
    "def text_to_vec(text):\n",
    "    return vectorizer.transform([text])\n",
    "\n",
    "initiative_vecs = {\n",
    "    name: text_to_vec(\" \".join(kws))\n",
    "    for name, kws in initiative_keywords.items()\n",
    "}\n",
    "initiative_names = list(initiative_vecs.keys())\n",
    "\n",
    "# Initial assignment: choose initiative with highest similarity\n",
    "assignments = {}\n",
    "for i, gid in enumerate(grant_ids):\n",
    "    g_vec = grant_vecs[i]\n",
    "    best_init = None\n",
    "    best_score = -1\n",
    "    for init_name, init_vec in initiative_vecs.items():\n",
    "        score = cosine_similarity(g_vec, init_vec)[0, 0]\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_init = init_name\n",
    "    assignments[gid] = best_init\n",
    "\n",
    "def recompute_initiative_centroids(assignments, grant_vecs, grants_df):\n",
    "    new_vecs = {}\n",
    "    for init_name in initiative_names:\n",
    "        idx = [i for i, gid in enumerate(grants_df[\"grant_id\"]) if assignments[gid] == init_name]\n",
    "        if not idx:\n",
    "            new_vecs[init_name] = initiative_vecs[init_name]  # keep old\n",
    "        else:\n",
    "            mat = grant_vecs[idx]\n",
    "            centroid = mat.mean(axis=0)\n",
    "            new_vecs[init_name] = centroid\n",
    "    return new_vecs\n",
    "\n",
    "def total_similarity(assignments, init_vecs, grant_vecs, grants_df):\n",
    "    total = 0.0\n",
    "    for i, gid in enumerate(grants_df[\"grant_id\"]):\n",
    "        g_vec = grant_vecs[i]\n",
    "        init_name = assignments[gid]\n",
    "        init_vec = init_vecs[init_name]\n",
    "        total += cosine_similarity(g_vec, init_vec)[0, 0]\n",
    "    return total\n",
    "\n",
    "# Steepest-ascent hill climbing\n",
    "max_iters = 10\n",
    "for it in range(max_iters):\n",
    "    initiative_vecs = recompute_initiative_centroids(assignments, grant_vecs, grants)\n",
    "    base_score = total_similarity(assignments, initiative_vecs, grant_vecs, grants)\n",
    "    print(f\"Iteration {it}, total similarity = {base_score:.4f}\")\n",
    "\n",
    "    improved = False\n",
    "    # For each grant, try moving it to all other initiatives\n",
    "    for i, gid in enumerate(grant_ids):\n",
    "        current_init = assignments[gid]\n",
    "        best_init = current_init\n",
    "        best_score = base_score\n",
    "\n",
    "        for init_name in initiative_names:\n",
    "            if init_name == current_init:\n",
    "                continue\n",
    "            # Neighbor: move this grant to a different initiative\n",
    "            old_init = assignments[gid]\n",
    "            assignments[gid] = init_name\n",
    "            new_inits = recompute_initiative_centroids(assignments, grant_vecs, grants)\n",
    "            new_score = total_similarity(assignments, new_inits, grant_vecs, grants)\n",
    "            if new_score > best_score:\n",
    "                best_score = new_score\n",
    "                best_init = init_name\n",
    "            assignments[gid] = old_init  # revert\n",
    "\n",
    "        if best_init != current_init:\n",
    "            assignments[gid] = best_init\n",
    "            improved = True\n",
    "\n",
    "    if not improved:\n",
    "        print(\"No improving moves found (local optimum).\")\n",
    "        break\n",
    "\n",
    "grants[\"initiative_local_search\"] = grants[\"grant_id\"].map(assignments)\n",
    "grants[[\"grant_id\", \"initiative_local_search\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e75ad1-c879-4f66-8284-86e2e6f8d4f2",
   "metadata": {},
   "source": [
    "## 1.2 Local Search: Minimize Abstract–Program Mismatch\n",
    "\n",
    "Another local-search example:\n",
    "\n",
    "- **State**: assignment `grant_id → program_code`.\n",
    "- **Objective**: minimize average mismatch between a grant’s abstract and its program centroid.\n",
    "- **Cost function**: mismatch = 1 − cosine similarity.\n",
    "- **Neighbor**: move one grant from its current program to some other program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ecbd26-2f02-4155-8a46-353dff5049ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "programs = grants[\"program_code\"].dropna().unique()\n",
    "\n",
    "# Start with current program assignments\n",
    "prog_assign = dict(zip(grant_ids, grants[\"program_code\"]))\n",
    "\n",
    "def compute_program_centroids(assignments):\n",
    "    centroids = {}\n",
    "    for prog in programs:\n",
    "        idx = [i for i, gid in enumerate(grant_ids) if assignments.get(gid) == prog]\n",
    "        if not idx:\n",
    "            continue\n",
    "        centroids[prog] = grant_vecs[idx].mean(axis=0)\n",
    "    return centroids\n",
    "\n",
    "def avg_mismatch(assignments, centroids):\n",
    "    mismatches = []\n",
    "    for i, gid in enumerate(grant_ids):\n",
    "        prog = assignments.get(gid)\n",
    "        if prog not in centroids:\n",
    "            continue\n",
    "        sim = cosine_similarity(grant_vecs[i], centroids[prog])[0, 0]\n",
    "        mismatches.append(1 - sim)  # mismatch\n",
    "    return np.mean(mismatches) if mismatches else np.nan\n",
    "\n",
    "max_iters = 10\n",
    "for it in range(max_iters):\n",
    "    centroids = compute_program_centroids(prog_assign)\n",
    "    base_mismatch = avg_mismatch(prog_assign, centroids)\n",
    "    print(f\"Iteration {it}, avg mismatch = {base_mismatch:.4f}\")\n",
    "\n",
    "    improved = False\n",
    "    for i, gid in enumerate(grant_ids):\n",
    "        current_prog = prog_assign.get(gid)\n",
    "        best_prog = current_prog\n",
    "        best_mismatch = base_mismatch\n",
    "\n",
    "        for prog in programs:\n",
    "            if prog == current_prog:\n",
    "                continue\n",
    "            old = prog_assign[gid]\n",
    "            prog_assign[gid] = prog\n",
    "            new_centroids = compute_program_centroids(prog_assign)\n",
    "            new_mismatch = avg_mismatch(prog_assign, new_centroids)\n",
    "            if new_mismatch < best_mismatch:\n",
    "                best_mismatch = new_mismatch\n",
    "                best_prog = prog\n",
    "            prog_assign[gid] = old\n",
    "\n",
    "        if best_prog != current_prog:\n",
    "            prog_assign[gid] = best_prog\n",
    "            improved = True\n",
    "\n",
    "    if not improved:\n",
    "        print(\"Reached local minimum (no better neighbor).\")\n",
    "        break\n",
    "\n",
    "grants[\"program_local_search\"] = [prog_assign[gid] for gid in grant_ids]\n",
    "grants[[\"grant_id\", \"program_code\", \"program_local_search\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15952bca-0453-4bd1-8332-da726df9c00a",
   "metadata": {},
   "source": [
    "## 2. Linear Programming: Budget to Maximize Impact\n",
    "\n",
    "We’ll model:\n",
    "\n",
    "- **Decision variables**:\n",
    "  - \\( x_g \\in \\{0,1\\} \\): 1 if grant \\( g \\) is funded, 0 otherwise.\n",
    "- **Objective (maximize)**:\n",
    "  - Sum of expected citations: \\( \\sum_g \\text{citations}_g \\cdot x_g \\).\n",
    "- **Constraints**:\n",
    "  - Total budget: \\( \\sum_g \\text{cost}_g \\cdot x_g \\leq B \\).\n",
    "  - Optional equity constraints (e.g., LMIC share, initiative minima).\n",
    "\n",
    "We’ll use `pulp` to solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af786bc-5b60-47e0-af7a-b8b4146dcb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "grants_lp = grants.dropna(subset=[\"total_funding\", \"citations_5yr\"]).copy()\n",
    "\n",
    "BUDGET = 100_000_000  # adjust as needed\n",
    "\n",
    "prob = pulp.LpProblem(\"Budget_to_Maximize_Impact\", pulp.LpMaximize)\n",
    "\n",
    "# Decision variables\n",
    "x = {\n",
    "    row.grant_id: pulp.LpVariable(f\"x_{row.grant_id}\", cat=\"Binary\")\n",
    "    for _, row in grants_lp.iterrows()\n",
    "}\n",
    "\n",
    "# Objective: maximize total citations\n",
    "prob += pulp.lpSum(row.citations_5yr * x[row.grant_id]\n",
    "                   for _, row in grants_lp.iterrows())\n",
    "\n",
    "# Budget constraint\n",
    "prob += pulp.lpSum(row.total_funding * x[row.grant_id]\n",
    "                   for _, row in grants_lp.iterrows()) <= BUDGET\n",
    "\n",
    "# Solve\n",
    "prob.solve(pulp.PULP_CBC_CMD(msg=False))\n",
    "print(\"Status:\", pulp.LpStatus[prob.status])\n",
    "\n",
    "grants_lp[\"funded_lp\"] = grants_lp[\"grant_id\"].apply(lambda gid: int(pulp.value(x[gid])))\n",
    "grants_lp[[\"grant_id\", \"total_funding\", \"citations_5yr\", \"funded_lp\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f420aa41-49cd-4afa-ac7a-613d70413e7d",
   "metadata": {},
   "source": [
    "### LP with Cost and Equity Constraints\n",
    "\n",
    "Add:\n",
    "\n",
    "- **LMIC share constraint**: at least 30% of budget to LMIC/LIC grants.\n",
    "- **Initiative minimum share**: each initiative gets at least 5% of the funded budget.\n",
    "\n",
    "This mimics **policy constraints** (equity and portfolio balance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07de383-093b-4161-becd-d11e72b0bcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume grants_lp has columns: country_income_level, initiative\n",
    "grants_lp = grants_lp.dropna(subset=[\"country_income_level\", \"initiative\"])\n",
    "\n",
    "BUDGET = 100_000_000\n",
    "LMIC_SHARE = 0.30\n",
    "MIN_INIT_SHARE = 0.05\n",
    "\n",
    "prob2 = pulp.LpProblem(\"Maximize_Impact_With_Equity\", pulp.LpMaximize)\n",
    "\n",
    "x2 = {\n",
    "    row.grant_id: pulp.LpVariable(f\"x_{row.grant_id}\", cat=\"Binary\")\n",
    "    for _, row in grants_lp.iterrows()\n",
    "}\n",
    "\n",
    "# Objective\n",
    "prob2 += pulp.lpSum(row.citations_5yr * x2[row.grant_id]\n",
    "                    for _, row in grants_lp.iterrows())\n",
    "\n",
    "# Total budget\n",
    "total_budget = pulp.lpSum(row.total_funding * x2[row.grant_id]\n",
    "                          for _, row in grants_lp.iterrows())\n",
    "prob2 += total_budget <= BUDGET\n",
    "\n",
    "# LMIC/LIC budget share\n",
    "lmic_rows = grants_lp[grants_lp[\"country_income_level\"].isin([\"LMIC\", \"LIC\"])]\n",
    "lmic_budget = pulp.lpSum(row.total_funding * x2[row.grant_id]\n",
    "                         for _, row in lmic_rows.iterrows())\n",
    "prob2 += lmic_budget >= LMIC_SHARE * total_budget\n",
    "\n",
    "# Initiative minimum share\n",
    "for init in grants_lp[\"initiative\"].dropna().unique():\n",
    "    init_rows = grants_lp[grants_lp[\"initiative\"] == init]\n",
    "    init_budget = pulp.lpSum(row.total_funding * x2[row.grant_id]\n",
    "                             for _, row in init_rows.iterrows())\n",
    "    prob2 += init_budget >= MIN_INIT_SHARE * total_budget\n",
    "\n",
    "# Solve\n",
    "prob2.solve(pulp.PULP_CBC_CMD(msg=False))\n",
    "print(\"Status:\", pulp.LpStatus[prob2.status])\n",
    "\n",
    "grants_lp[\"funded_equity_lp\"] = grants_lp[\"grant_id\"].apply(lambda gid: int(pulp.value(x2[gid])))\n",
    "grants_lp[[\"grant_id\", \"initiative\", \"country_income_level\", \"funded_equity_lp\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4224812e-d87b-4049-989c-d8c795fd6eb3",
   "metadata": {},
   "source": [
    "## 3. Constraint Satisfaction: Reviewer Assignment\n",
    "\n",
    "Treat **reviewer assignment** as a CSP:\n",
    "\n",
    "- **Variables**: assignment decisions \\( y_{g,r} \\) (0/1: does reviewer \\( r \\) review grant \\( g \\)?).\n",
    "- **Domains**: {0,1} for each pair (subject to constraints).\n",
    "- **Constraints**:\n",
    "  - Each grant has between R_MIN and R_MAX reviewers.\n",
    "  - Each reviewer has a maximum load.\n",
    "  - Conflicts-of-interest: certain (grant, reviewer) pairs forbidden.\n",
    "  - (Optional) topic-fit: ensure similarity exceeds a threshold.\n",
    "\n",
    "Implement this as an **integer linear program** (MIP) — a common way to solve CSPs in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b588b4da-628d-4f0a-977e-8e5048064565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic CSP with load & conflicts (no topic similarity yet)\n",
    "\n",
    "grant_ids = grants[\"grant_id\"].tolist()\n",
    "reviewer_ids = reviewers[\"reviewer_id\"].tolist()\n",
    "conflict_set = set(zip(conflicts[\"grant_id\"], conflicts[\"reviewer_id\"]))\n",
    "\n",
    "R_MIN = 2\n",
    "R_MAX = 3\n",
    "\n",
    "prob_csp = pulp.LpProblem(\"Assign_Reviewers\", pulp.LpMaximize)\n",
    "\n",
    "# Decision variables y_(g,r) defined only if no conflict\n",
    "y = {\n",
    "    (g, r): pulp.LpVariable(f\"y_{g}_{r}\", cat=\"Binary\")\n",
    "    for g in grant_ids\n",
    "    for r in reviewer_ids\n",
    "    if (g, r) not in conflict_set\n",
    "}\n",
    "\n",
    "# Simple objective: maximize number of assignments (feasible solution)\n",
    "prob_csp += pulp.lpSum(y.values())\n",
    "\n",
    "# Constraint: reviewer count per grant\n",
    "for g in grant_ids:\n",
    "    reviewers_for_g = [y[(g, r)] for r in reviewer_ids if (g, r) in y]\n",
    "    if reviewers_for_g:\n",
    "        prob_csp += pulp.lpSum(reviewers_for_g) >= R_MIN\n",
    "        prob_csp += pulp.lpSum(reviewers_for_g) <= R_MAX\n",
    "\n",
    "# Constraint: max load per reviewer\n",
    "max_load_map = dict(zip(reviewers[\"reviewer_id\"], reviewers[\"max_load\"]))\n",
    "for r in reviewer_ids:\n",
    "    grants_for_r = [y[(g, r)] for g in grant_ids if (g, r) in y]\n",
    "    if grants_for_r:\n",
    "        prob_csp += pulp.lpSum(grants_for_r) <= max_load_map[r]\n",
    "\n",
    "prob_csp.solve(pulp.PULP_CBC_CMD(msg=False))\n",
    "print(\"Status:\", pulp.LpStatus[prob_csp.status])\n",
    "\n",
    "assignments = []\n",
    "for (g, r), var in y.items():\n",
    "    if pulp.value(var) > 0.5:\n",
    "        assignments.append({\"grant_id\": g, \"reviewer_id\": r})\n",
    "\n",
    "assign_df = pd.DataFrame(assignments)\n",
    "assign_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbcf2a7-9414-4948-a3e3-64c0d98dccc4",
   "metadata": {},
   "source": [
    "### CSP with Topic Similarity\n",
    "\n",
    "We can refine:\n",
    "\n",
    "- Only allow assignments where topic similarity ≥ threshold.\n",
    "- Maximize **sum of similarities** rather than just count.\n",
    "\n",
    "We’ll:\n",
    "\n",
    "1. Create TF-IDF representations of grant abstracts and reviewer expertise.\n",
    "2. Compute cosine similarity for (grant, reviewer) pairs.\n",
    "3. Keep only pairs above a similarity threshold.\n",
    "4. Solve MIP to maximize total similarity under CSP constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88dfea9-6d73-4419-99e8-3e3300c663c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Build a joint vocabulary for abstracts + expertise\n",
    "texts = pd.concat([\n",
    "    grants[\"abstract\"].fillna(\"\"),\n",
    "    reviewers[\"expertise_topics\"].fillna(\"\")\n",
    "], ignore_index=True)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.8, min_df=1)\n",
    "X_text = vectorizer.fit_transform(texts)\n",
    "\n",
    "G = len(grants)\n",
    "R = len(reviewers)\n",
    "\n",
    "grant_vecs2 = X_text[:G]\n",
    "reviewer_vecs2 = X_text[G:]\n",
    "\n",
    "sim_matrix = cosine_similarity(grant_vecs2, reviewer_vecs2)\n",
    "\n",
    "grant_ids = grants[\"grant_id\"].tolist()\n",
    "reviewer_ids = reviewers[\"reviewer_id\"].tolist()\n",
    "\n",
    "# Map similarity scores\n",
    "sim = {\n",
    "    (grant_ids[i], reviewer_ids[j]): sim_matrix[i, j]\n",
    "    for i in range(G)\n",
    "    for j in range(R)\n",
    "}\n",
    "\n",
    "SIM_THRESHOLD = 0.1\n",
    "R_MIN = 2\n",
    "R_MAX = 3\n",
    "conflict_set = set(zip(conflicts[\"grant_id\"], conflicts[\"reviewer_id\"]))\n",
    "\n",
    "prob_csp2 = pulp.LpProblem(\"Match_Reviewers_Topic\", pulp.LpMaximize)\n",
    "\n",
    "# Variables only where no conflict and similarity above threshold\n",
    "y2 = {}\n",
    "for g in grant_ids:\n",
    "    for r in reviewer_ids:\n",
    "        if (g, r) in conflict_set:\n",
    "            continue\n",
    "        if sim[(g, r)] < SIM_THRESHOLD:\n",
    "            continue\n",
    "        y2[(g, r)] = pulp.LpVariable(f\"y_{g}_{r}\", cat=\"Binary\")\n",
    "\n",
    "# Objective: maximize total similarity\n",
    "prob_csp2 += pulp.lpSum(sim[(g, r)] * var for (g, r), var in y2.items())\n",
    "\n",
    "# Grant constraints\n",
    "for g in grant_ids:\n",
    "    reviewers_for_g = [y2[(g, r)] for r in reviewer_ids if (g, r) in y2]\n",
    "    if reviewers_for_g:\n",
    "        prob_csp2 += pulp.lpSum(reviewers_for_g) >= R_MIN\n",
    "        prob_csp2 += pulp.lpSum(reviewers_for_g) <= R_MAX\n",
    "\n",
    "# Reviewer load\n",
    "max_load_map = dict(zip(reviewers[\"reviewer_id\"], reviewers[\"max_load\"]))\n",
    "for r in reviewer_ids:\n",
    "    grants_for_r = [y2[(g, r)] for g in grant_ids if (g, r) in y2]\n",
    "    if grants_for_r:\n",
    "        prob_csp2 += pulp.lpSum(grants_for_r) <= max_load_map[r]\n",
    "\n",
    "prob_csp2.solve(pulp.PULP_CBC_CMD(msg=False))\n",
    "print(\"Status:\", pulp.LpStatus[prob_csp2.status])\n",
    "\n",
    "assignments2 = []\n",
    "for (g, r), var in y2.items():\n",
    "    if pulp.value(var) > 0.5:\n",
    "        assignments2.append({\n",
    "            \"grant_id\": g,\n",
    "            \"reviewer_id\": r,\n",
    "            \"similarity\": sim[(g, r)]\n",
    "        })\n",
    "\n",
    "assign2_df = pd.DataFrame(assignments2)\n",
    "assign2_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e0517b-20c7-4966-b510-80c6e1672efd",
   "metadata": {},
   "source": [
    "## 1. Local Search\n",
    "\n",
    "- **Hill climbing** over:\n",
    "  - Assignments of grants to initiatives.\n",
    "  - Assignments of grants to programs.\n",
    "- Showed how we:\n",
    "  - Defined a **state** (mapping grants → labels),\n",
    "  - Defined **neighbors** (move one grant),\n",
    "  - Used an **objective** (similarity / mismatch).\n",
    "\n",
    "Variants you could add:\n",
    "- **Stochastic hill climbing**: randomly select improving neighbors.\n",
    "- **Random-restart**: rerun from multiple random initial assignments.\n",
    "- **Simulated annealing**: occasionally accept worse moves early via a temperature schedule.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Linear Programming\n",
    "\n",
    "- Formulated a **budget allocation** problem:\n",
    "  - Maximize total citations under a budget.\n",
    "- Added **equity constraints**:\n",
    "  - Minimum LMIC share.\n",
    "  - Minimum initiative share.\n",
    "\n",
    "LP gives **exact solutions** for linear objectives & constraints (subject to solver precision).\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Constraint Satisfaction Problems (CSPs)\n",
    "\n",
    "- Assigned reviewers to grants subject to:\n",
    "  - Reviewer load\n",
    "  - Conflicts-of-interest\n",
    "  - Minimum/maximum reviewers per grant\n",
    "  - Optional topic similarity thresholds\n",
    "\n",
    "We used integer programming (`pulp`) as a practical solver for CSP-style problems.\n",
    "\n",
    "---\n",
    "\n",
    "## Concept Mapping\n",
    "\n",
    "| Technique             | Problem                                    | Dimensions Example                                                   |\n",
    "|-----------------------|--------------------------------------------|---------------------------------------------------------------------|\n",
    "| **Local Search**      | Approximate optimization over assignments  | Grant → initiative, Grant → program (minimize mismatch)             |\n",
    "| **Linear Programming**| Continuous / binary decision optimization  | Fund / not fund each grant under budget + equity constraints        |\n",
    "| **CSP / MIP**         | Valid assignments under constraints        | Reviewer → grant assignments with conflicts and load constraints    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9f582b-faf2-46eb-9d05-75283ea55bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
